---
---
<p style="font-size:18px;">Due to legal or technical constraints, and the fact that labeling data is expensive and time-consuming, real-world deep-learning pipelines would rarely involve a single fine-tuning stage. Instead, these pipelines could require the sequential fine-tuning of large models in a set of independent tasks that are learned sequentially. Under these conditions, deep neural networks suffer from what is known as catastrophic forgetting, where the fine-tuning on novel tasks significantly reduces the performance of the model in a previously learned task, and drift, where unseen training data does not fit the previously estimated class
distribution. Continual learning directly models such a scenario, by adapting a neural network model into a sequential series of tasks. We focus on a special case of CL: class incremental learning (CIL), where the labels and data are mutually exclusive between tasks, training data is available only for the current task, and there are no tasks ids.</p>
